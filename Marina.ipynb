{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np              # NumPy, for working with arrays/tensors \n",
    "import time                     # For measuring time\n",
    "import random                   # Python's random library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# PyTorch libraries:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Cuda (GPU support) is available and enabled!\")\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  print(\"Cuda (GPU support) is not available :(\")\n",
    "  device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "LABELS_FILEPATH = \"./SMAP MSL/labeled_anomalies.csv\"\n",
    "TRAINSET_FILEPATH = \"./SMAP MSL/data/data/train\"\n",
    "TESTSET_FILEPATH = \"./SMAP MSL/data/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "labels.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#training params\n",
    "BATCH_SIZE = 128\n",
    "INPUT_LENGTH = 100\n",
    "INTERMEDIATE_LENGTH = 24\n",
    "ALPHA  =0.1\n",
    "DIMENSIONS  = 25 \n",
    "lr = 0.005\n",
    "#optimizer = torch.optim.Adam(lr = lr )\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#data loading \n",
    "import os\n",
    "train_datas = {}\n",
    "test_datas = {}\n",
    "arranged_train_datas = {}\n",
    "arranged_test_datas = {}\n",
    "# Iterate directory\n",
    "for path in os.listdir(TRAINSET_FILEPATH):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(TRAINSET_FILEPATH, path)):\n",
    "        train_data = np.load(os.path.join(TRAINSET_FILEPATH, path))\n",
    "        train_datas[path] = train_data\n",
    "for path in os.listdir(TESTSET_FILEPATH):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(TESTSET_FILEPATH, path)):\n",
    "        test_data = np.load(os.path.join(TESTSET_FILEPATH, path))\n",
    "        test_datas[path] = test_data\n",
    "\n",
    "for train_data in train_datas:\n",
    "    print(train_datas[train_data ].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#4.1 data normalization \n",
    "#1 - training normalization \n",
    "for train_data in train_datas:\n",
    "    train_datas[train_data] = normalize(train_datas[train_data])\n",
    "    train_datas[train_data] =  train_datas[train_data] * 2 - 1\n",
    "#2 - test normalization\n",
    "test_means = {}\n",
    "test_variances = {}\n",
    "\n",
    "for test_data in test_datas:\n",
    "    mean = 0\n",
    "    variance = 1\n",
    "    # generate expected value of for discrete datas\n",
    "    expected_values = {}\n",
    "    for row in test_datas[test_data]:\n",
    "        for element in row:\n",
    "            if element in expected_values:\n",
    "                expected_values[element] += 1\n",
    "            else:\n",
    "                expected_values[element] = 0\n",
    "                \n",
    "    sum = 0\n",
    "    for keys in expected_values:\n",
    "        sum += expected_values[keys] \n",
    "\n",
    "    for keys in expected_values:\n",
    "        expected_values[keys] /= sum\n",
    "\n",
    "    #now we got expected values\n",
    "    #iterate through data\n",
    "    for row in test_datas[test_data]:\n",
    "        for element in row:\n",
    "            mean = (1 - ALPHA) * mean + ALPHA * expected_values[element]\n",
    "            e_x_2 = 0\n",
    "            if (element*element) in expected_values:\n",
    "                e_x_2 = expected_values[element*element]\n",
    "            variance = (1 - ALPHA) * variance + ALPHA * ( e_x_2 - expected_values[element] * expected_values[element]  )\n",
    "            test_means[test_data + \"_\" + str(row) + \"_\" + str(element)] = mean \n",
    "            test_variances[test_data + \"_\" + str(row) + \"_\" + str(element)] = variance \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "                 \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#4.2 temporal correlation\n",
    "#inout sub block \n",
    "\n",
    "\n",
    "class InputSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InputSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_LENGTH, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.fc4 = nn.Linear(50, 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "#cascade sub block \n",
    "class CascadeSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CascadeSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_LENGTH, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, INPUT_LENGTH)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "#forecasting sub block\n",
    "class ForecastingSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ForecastingSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_LENGTH, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, INTERMEDIATE_LENGTH)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "#MLPBlock\n",
    "class MLPBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.input = InputSubBlock()\n",
    "        self.cascade = CascadeSubBlock()\n",
    "        self.forecasting = ForecastingSubBlock()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        cascade = self.cascade(x)\n",
    "        forecast = self.forecasting(x)\n",
    "        return cascade , forecast\n",
    "class TemporalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemporalModule, self).__init__()\n",
    "        self.mlp1 = MLPBlock() \n",
    "        self.mlp2 = MLPBlock() \n",
    "\n",
    "    def forward(self, input):\n",
    "        mlp1_out , forecast = self.mlp1(input)\n",
    "        new_input = mlp1_out - input \n",
    "        mlp2_out , forecast_2 = self.mlp2(new_input)\n",
    "        return (forecast + forecast_2)\n",
    "\n",
    "s = TemporalModule()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b369e7963f7abcd480fad95d5beb7b146f8ec315fde1b361e4f21d5ea962be01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
