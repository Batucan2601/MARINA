{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda (GPU support) is not available :(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np              # NumPy, for working with arrays/tensors \n",
    "import time                     # For measuring time\n",
    "import random                   # Python's random library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# PyTorch libraries:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Cuda (GPU support) is available and enabled!\")\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  print(\"Cuda (GPU support) is not available :(\")\n",
    "  device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_FILEPATH = \"./SMAP MSL/labeled_anomalies.csv\"\n",
    "TRAINSET_FILEPATH = \"./SMAP MSL/data/data/train\"\n",
    "TESTSET_FILEPATH = \"./SMAP MSL/data/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   chan_id            82 non-null     object\n",
      " 1   spacecraft         82 non-null     object\n",
      " 2   anomaly_sequences  82 non-null     object\n",
      " 3   class              82 non-null     object\n",
      " 4   num_values         82 non-null     int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chan_id</th>\n",
       "      <th>spacecraft</th>\n",
       "      <th>anomaly_sequences</th>\n",
       "      <th>class</th>\n",
       "      <th>num_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[2149, 2349], [4536, 4844], [3539, 3779]]</td>\n",
       "      <td>[contextual, contextual, contextual]</td>\n",
       "      <td>8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5300, 5747]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-1</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5000, 5030], [5610, 6086]]</td>\n",
       "      <td>[contextual, contextual]</td>\n",
       "      <td>8516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-2</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5598, 6995]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-3</td>\n",
       "      <td>SMAP</td>\n",
       "      <td>[[5094, 8306]]</td>\n",
       "      <td>[point]</td>\n",
       "      <td>8307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chan_id spacecraft                           anomaly_sequences   \n",
       "0     P-1       SMAP  [[2149, 2349], [4536, 4844], [3539, 3779]]  \\\n",
       "1     S-1       SMAP                              [[5300, 5747]]   \n",
       "2     E-1       SMAP                [[5000, 5030], [5610, 6086]]   \n",
       "3     E-2       SMAP                              [[5598, 6995]]   \n",
       "4     E-3       SMAP                              [[5094, 8306]]   \n",
       "\n",
       "                                  class  num_values  \n",
       "0  [contextual, contextual, contextual]        8505  \n",
       "1                               [point]        7331  \n",
       "2              [contextual, contextual]        8516  \n",
       "3                               [point]        8532  \n",
       "4                               [point]        8307  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS_FILEPATH)\n",
    "labels.info()\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading \n",
    "# T-10 data is not in Labels but in Train Dataset. Therefore, T-10 will not be used for now.\n",
    "import os\n",
    "train_datas = {}\n",
    "test_datas = {}\n",
    "arranged_train_datas = {}\n",
    "arranged_test_datas = {}\n",
    "\n",
    "desiredSC      = 'SMAP'\n",
    "# Iterate directory\n",
    "for path in os.listdir(TRAINSET_FILEPATH):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(TRAINSET_FILEPATH, path)):\n",
    "        if path != 'T-10.npy':\n",
    "            SC_labels     = labels[labels['chan_id'] == path.replace('.npy','')]\n",
    "            SC            = SC_labels['spacecraft']\n",
    "            # print(\"SC_labels\",SC_labels)\n",
    "            # print(\"SC\",SC)\n",
    "            # print((SC.iloc[0]),path.replace('.npy',''))\n",
    "            SC_name       = SC.iloc[0]\n",
    "            if SC_name == desiredSC:\n",
    "                train_data = np.load(os.path.join(TRAINSET_FILEPATH, path))\n",
    "                train_datas[path] = train_data\n",
    "\n",
    "for path in os.listdir(TESTSET_FILEPATH):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(TESTSET_FILEPATH, path)):\n",
    "        if path != 'T-10.npy':\n",
    "            SC_labels     = labels[labels['chan_id'] == path.replace('.npy','')]\n",
    "            SC            = SC_labels['spacecraft']\n",
    "            SC_name       = SC.iloc[0]\n",
    "            if SC_name == desiredSC:       \n",
    "                test_data = np.load(os.path.join(TESTSET_FILEPATH, path))\n",
    "                test_datas[path] = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing Functions\n",
    "\n",
    "def windowed_Set(original_data, window_size, shifting,horizon):\n",
    "    time_sequence_length, n_dimensions  = original_data.shape\n",
    "    T = int((time_sequence_length - window_size-horizon) / shifting + 1)\n",
    "    \n",
    "    windowedArray = np.empty((n_dimensions, T, window_size))\n",
    "    futuredArray  = np.empty((n_dimensions, T, horizon))\n",
    "\n",
    "    for d in range(n_dimensions):\n",
    "        for i in range(T):\n",
    "            start_index = i * shifting\n",
    "            window       = original_data[start_index : start_index + window_size,d]\n",
    "            horizon_data = original_data[start_index + window_size : start_index + window_size + horizon,d]\n",
    "            windowedArray[d, i, :] = window\n",
    "            futuredArray[d, i, :]  = horizon_data\n",
    "    return windowedArray, futuredArray\n",
    "\n",
    "def normalize_data(data_, desired_mean, desired_std):\n",
    "    \"\"\"This code turns the input into have the desired mean and variance values. When standard deviation is zero, \n",
    "       since division will be infinity, it will bypass.\n",
    "    \"\"\"\n",
    "    # Calculate the mean and variance of the original data\n",
    "    data = data_.copy()\n",
    "    original_mean = np.mean(data)\n",
    "    original_std = np.std(data)\n",
    "     \n",
    "    # Subtract the mean from each data point\n",
    "    data -= original_mean\n",
    "    # Divide each data point by the square root of the variance\n",
    "    if original_std != 0:\n",
    "        data /= original_std\n",
    "        # Multiply each data point by the desired standard deviation\n",
    "        data *= desired_std\n",
    "    # Add the desired mean to each data point\n",
    "    data += desired_mean\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total set number is: 54 \n",
      "1 Set name: T-3.npy \n",
      "Set shape: (2876, 25) [t,D] \n",
      "Windowed array shape: (25, 556, 100) [D,i,w] \n",
      "Futured array shape: (25, 556, 1) [D,i,zeta] \n",
      "One sample mean: 1.3242382001648598e-16 \n",
      "One sample dimension variance: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Normalization Parameters\n",
    "INPUT_LENGTH = 100\n",
    "wL = INPUT_LENGTH     # window length\n",
    "zeta = 1             # horizon length (future length to predict)\n",
    "shift = 5\n",
    "\n",
    "#4.1 data normalization \n",
    "#1 - training normalization \n",
    "train_means = {}\n",
    "train_variances = {}\n",
    "windowedTrain = {}      # Dividing the data with windows\n",
    "futuredTrain = {}       # Creating arrays to be futured\n",
    "\n",
    "for train_data in train_datas:\n",
    "    #print(train_datas[train_data].shape)\n",
    "    D                                       = train_datas[train_data].shape[1]\n",
    "    iN                                      = train_datas[train_data].shape[0]\n",
    "\n",
    "    for D_ in range(D):\n",
    "        train_datas[train_data][:,D_]       = normalize_data(train_datas[train_data][:,D_],0,1)\n",
    "    #train_datas[train_data] = train_datas[train_data] * 2 - 1  # variance 1 olacak teyit et\n",
    "    \n",
    "    windowedTrain[train_data], futuredTrain[train_data] = windowed_Set(train_datas[train_data],wL,shift,zeta)\n",
    "\n",
    "print(\"Total set number is:\",len(windowedTrain),\n",
    "      \"\\n1 Set name:\",train_data,\n",
    "      \"\\nSet shape:\",train_datas[train_data].shape,\"[t,D]\",\n",
    "      \"\\nWindowed array shape:\",windowedTrain[train_data].shape,\"[D,i,w]\",\n",
    "      \"\\nFutured array shape:\",futuredTrain[train_data].shape,\"[D,i,zeta]\",\n",
    "      \"\\nOne sample mean:\", np.mean(train_datas[train_data]),\n",
    "      \"\\nOne sample dimension variance:\", np.std(train_datas[train_data][:,0]))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining intermediate length and alpha before designing the modules\n",
    "INTERMEDIATE_LENGTH         = 24\n",
    "ALPHA                       = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window length: 100 \n",
      "Shifting: 5 \n",
      "Horizon (zeta): 1 \n",
      "Total set number is: 54 \n",
      "1 Set name: T-3.npy \n",
      "Set shape: (8579, 25) [t,D] \n",
      "Windowed array shape: (25, 1696, 100) [D,i,w] \n",
      "Futured array shape: (25, 1696, 1) [D,i,zeta] \n",
      "Test means array shape: (25, 2) [D,i] \n",
      "Test variance array shape: (25, 2) [D,i]\n"
     ]
    }
   ],
   "source": [
    "windowedTest    = {}\n",
    "futuredTest     = {}\n",
    "test_means      = {}\n",
    "test_variances  = {}\n",
    "test_std        = {}\n",
    "\n",
    "for test_data in test_datas:\n",
    "    windowedTest[test_data], futuredTest[test_data] = windowed_Set(test_datas[test_data],wL,shift,zeta)\n",
    "\n",
    "for test_data in test_datas:\n",
    "    #print(test_datas[test_data].shape)\n",
    "    D                               = windowedTest[test_data].shape[0]\n",
    "    iN                              = windowedTest[test_data].shape[1]\n",
    "    iN=2\n",
    "\n",
    "    test_means[test_data]           = np.zeros((D,iN))\n",
    "    test_variances[test_data]       = np.zeros((D,iN))\n",
    "    test_std[test_data]             = np.zeros((D,iN))\n",
    "    test_means[test_data][:,0]      = 0\n",
    "    test_std[test_data][:,0]        = 0\n",
    "    test_variances[test_data][:,0]  = 1 \n",
    "\n",
    "    for iN_ in range(1,iN): \n",
    "        E                                = np.mean(windowedTest[test_data][:,iN_,:],axis = 1)\n",
    "        E2                               = np.mean(windowedTest[test_data][:,iN_,:]**2,axis = 1)    \n",
    "        test_means[test_data][:,iN_]     = (1-ALPHA)*test_means[test_data][:,iN_-1] + ALPHA*E \n",
    "        test_variances[test_data][:,iN_] = (1-ALPHA)*test_variances[test_data][:,iN_-1]+ALPHA*(E2-E**2)\n",
    "        test_std[test_data][:,iN_]       = np.sqrt(test_variances[test_data][:,iN_-1])\n",
    "        for D_ in range(D):\n",
    "            dynamicMean                       = test_means[test_data][D_,iN_-1]\n",
    "            dynamicVar                        = test_variances[test_data][D_,iN_-1]\n",
    "            dynamicStd                        = test_std[test_data][D_,iN_-1]\n",
    "            \n",
    "            windowedTest[test_data][D_,iN_,:] = normalize_data(windowedTest[test_data][D_,iN_,:],dynamicMean,dynamicStd)\n",
    "\n",
    "print(\"Window length:\", wL,\n",
    "      \"\\nShifting:\",shift,\n",
    "      \"\\nHorizon (zeta):\",zeta,\n",
    "      \"\\nTotal set number is:\",len(windowedTest),\n",
    "      \"\\n1 Set name:\",test_data,\n",
    "      \"\\nSet shape:\",test_datas[test_data].shape,\"[t,D]\",\n",
    "      \"\\nWindowed array shape:\",windowedTest[test_data].shape,\"[D,i,w]\",\n",
    "      \"\\nFutured array shape:\",futuredTest[test_data].shape,\"[D,i,zeta]\",\n",
    "      \"\\nTest means array shape:\",test_means[test_data].shape,\"[D,i]\",\n",
    "      \"\\nTest variance array shape:\",test_variances[test_data].shape,\"[D,i]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A-1.npy', 'A-2.npy', 'A-3.npy', 'A-4.npy', 'A-5.npy', 'A-6.npy', 'A-7.npy', 'A-8.npy', 'A-9.npy', 'B-1.npy', 'D-1.npy', 'D-11.npy', 'D-12.npy', 'D-13.npy', 'D-2.npy', 'D-3.npy', 'D-4.npy', 'D-5.npy', 'D-6.npy', 'D-7.npy', 'D-8.npy', 'D-9.npy', 'E-1.npy', 'E-10.npy', 'E-11.npy', 'E-12.npy', 'E-13.npy', 'E-2.npy', 'E-3.npy', 'E-4.npy', 'E-5.npy', 'E-6.npy', 'E-7.npy', 'E-8.npy', 'E-9.npy', 'F-1.npy', 'F-2.npy', 'F-3.npy', 'G-1.npy', 'G-2.npy', 'G-3.npy', 'G-4.npy', 'G-6.npy', 'G-7.npy', 'P-1.npy', 'P-2.npy', 'P-3.npy', 'P-4.npy', 'P-7.npy', 'R-1.npy', 'S-1.npy', 'T-1.npy', 'T-2.npy', 'T-3.npy'])\n",
      "\n",
      " dict_keys(['A-1.npy', 'A-2.npy', 'A-3.npy', 'A-4.npy', 'A-5.npy', 'A-6.npy', 'A-7.npy', 'A-8.npy', 'A-9.npy', 'B-1.npy', 'D-1.npy', 'D-11.npy', 'D-12.npy', 'D-13.npy', 'D-2.npy', 'D-3.npy', 'D-4.npy', 'D-5.npy', 'D-6.npy', 'D-7.npy', 'D-8.npy', 'D-9.npy', 'E-1.npy', 'E-10.npy', 'E-11.npy', 'E-12.npy', 'E-13.npy', 'E-2.npy', 'E-3.npy', 'E-4.npy', 'E-5.npy', 'E-6.npy', 'E-7.npy', 'E-8.npy', 'E-9.npy', 'F-1.npy', 'F-2.npy', 'F-3.npy', 'G-1.npy', 'G-2.npy', 'G-3.npy', 'G-4.npy', 'G-6.npy', 'G-7.npy', 'P-1.npy', 'P-2.npy', 'P-3.npy', 'P-4.npy', 'P-7.npy', 'R-1.npy', 'S-1.npy', 'T-1.npy', 'T-2.npy', 'T-3.npy'])\n",
      "\n",
      " ['P-1' 'S-1' 'E-1' 'E-2' 'E-3' 'E-4' 'E-5' 'E-6' 'E-7' 'E-8' 'E-9' 'E-10'\n",
      " 'E-11' 'E-12' 'E-13' 'A-1' 'D-1' 'P-2' 'P-3' 'D-2' 'D-3' 'D-4' 'A-2'\n",
      " 'A-3' 'A-4' 'G-1' 'G-2' 'D-5' 'D-6' 'D-7' 'F-1' 'P-4' 'G-3' 'T-1' 'T-2'\n",
      " 'D-8' 'D-9' 'F-2' 'G-4' 'T-3' 'D-11' 'D-12' 'B-1' 'G-6' 'G-7' 'P-7' 'R-1'\n",
      " 'A-5' 'A-6' 'A-7' 'D-13' 'P-2' 'A-8' 'A-9' 'F-3' 'M-6' 'M-1' 'M-2' 'S-2'\n",
      " 'P-10' 'T-4' 'T-5' 'F-7' 'M-3' 'M-4' 'M-5' 'P-15' 'C-1' 'C-2' 'T-12'\n",
      " 'T-13' 'F-4' 'F-5' 'D-14' 'T-9' 'P-14' 'T-8' 'P-11' 'D-15' 'D-16' 'M-7'\n",
      " 'F-8']\n"
     ]
    }
   ],
   "source": [
    "print(train_datas.keys())\n",
    "print('\\n',test_datas.keys())\n",
    "print('\\n',labels['chan_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 temporal correlation\n",
    "# in out sub block \n",
    "class InputSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InputSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_LENGTH, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.fc4 = nn.Linear(50, 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "# cascade sub block \n",
    "class CascadeSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CascadeSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(50, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, INPUT_LENGTH)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "#forecasting sub block\n",
    "class ForecastingSubBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ForecastingSubBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(50, 50)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(50, INTERMEDIATE_LENGTH)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "#MLPBlock\n",
    "class MLPBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.input = InputSubBlock()\n",
    "        self.cascade = CascadeSubBlock()\n",
    "        self.forecasting = ForecastingSubBlock()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"1\",x.shape)\n",
    "        x = self.input(x)\n",
    "        #print(\"2s\",x.shape)\n",
    "        cascade = self.cascade(x)\n",
    "        \n",
    "        forecast = self.forecasting(x)\n",
    "        \n",
    "        return cascade , forecast\n",
    "class TemporalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemporalModule, self).__init__()\n",
    "        self.mlp1 = MLPBlock() \n",
    "        self.mlp2 = MLPBlock() \n",
    "\n",
    "    def forward(self, input):\n",
    "        mlp1_out , forecast = self.mlp1(input)\n",
    "        new_input = mlp1_out - input \n",
    "        mlp2_out , forecast_2 = self.mlp2(new_input)\n",
    "        return (forecast + forecast_2)\n",
    "\n",
    "class SpatialModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialModule, self).__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=INTERMEDIATE_LENGTH, num_heads=8, dropout=0.05)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(INTERMEDIATE_LENGTH, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(50,INTERMEDIATE_LENGTH)            \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x, _ = self.self_attention(x, x, x)\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "    \n",
    "class OutputModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutputModule, self).__init__()\n",
    "        self.FFN = nn.Linear(INTERMEDIATE_LENGTH,1)\n",
    "    def forward(self, x):\n",
    "        x = self.FFN(x)\n",
    "        return x\n",
    "    \n",
    "class modeMARINA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(modeMARINA, self).__init__()\n",
    "        self.temporal = TemporalModule()\n",
    "        self.spatial  = SpatialModule()\n",
    "        self.output   = OutputModule()\n",
    "    def forward(self, x):\n",
    "        x = self.temporal(x)\n",
    "        x = self.spatial(x)\n",
    "        x = self.output(x)\n",
    "        return x  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarinaDataset(Dataset):\n",
    "    def __init__(self, vec,label):\n",
    "        self.vec = vec\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.vec)\n",
    "    def __getitem__(self, idx):        \n",
    "        return self.vec[idx], self.label[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A-1.npy', 'A-2.npy', 'A-3.npy', 'A-4.npy', 'A-5.npy', 'A-6.npy', 'A-7.npy', 'A-8.npy', 'A-9.npy', 'B-1.npy', 'D-1.npy', 'D-11.npy', 'D-12.npy', 'D-13.npy', 'D-2.npy', 'D-3.npy', 'D-4.npy', 'D-5.npy', 'D-6.npy', 'D-7.npy', 'D-8.npy', 'D-9.npy', 'E-1.npy', 'E-10.npy', 'E-11.npy', 'E-12.npy', 'E-13.npy', 'E-2.npy', 'E-3.npy', 'E-4.npy', 'E-5.npy', 'E-6.npy', 'E-7.npy', 'E-8.npy', 'E-9.npy', 'F-1.npy', 'F-2.npy', 'F-3.npy', 'G-1.npy', 'G-2.npy', 'G-3.npy', 'G-4.npy', 'G-6.npy', 'G-7.npy', 'P-1.npy', 'P-2.npy', 'P-3.npy', 'P-4.npy', 'P-7.npy', 'R-1.npy', 'S-1.npy', 'T-1.npy', 'T-2.npy', 'T-3.npy'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowedTest.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length of whole trainDataT: 26536 , and shape of input torch.Size([25, 100]) \n",
      "Length of whole futured (targets) list: 26536 , and shape of output torch.Size([25, 1])\n",
      "\n",
      "List length of whole testSet: 86104 , and shape of input torch.Size([25, 100]) \n",
      "Length of whole futured test (targets) list: 86104 , and shape of output torch.Size([25, 1])\n"
     ]
    }
   ],
   "source": [
    "# Stacking all data\n",
    "alltrainDataT      = []    # Create a list for training data\n",
    "allfuturedTrainT   = []    \n",
    "testSet          = []  \n",
    "test_futured       = [] \n",
    "\n",
    "testSetIdx         = []\n",
    "for i,name in enumerate(windowedTrain.keys()):\n",
    "    for j in range(windowedTrain[name].shape[1]):                                 # Looping over T dimension for stacking                              \n",
    "        alltrainDataT.append(torch.tensor(windowedTrain[name][:,0,:]).float())   # Swapping the dimensions accordingly as (T,D,W).\n",
    "        allfuturedTrainT.append(torch.tensor(futuredTrain[name][:,0,:]).float()) # Swapping the dimensions accordingly as (T,D,W).\n",
    "      \n",
    "for i,name in enumerate(windowedTest.keys()):\n",
    "    for j in range(windowedTest[name].shape[1]):                                 # Looping over T dimension for stacking                              \n",
    "        testSet.append(torch.tensor(windowedTest[name][:,0,:]).float())   # Swapping the dimensions accordingly as (T,D,W).\n",
    "        test_futured.append(torch.tensor(futuredTest[name][:,0,:]).float()) # Swapping the dimensions accordingly as (T,D,W).\n",
    "        testSetIdx.append([name, wL + zeta + shift*j - 1])\n",
    "\n",
    "    #print(windowedTrain[name].shape)\n",
    "print(\"List length of whole trainDataT:\",len(alltrainDataT),\", and shape of input\",alltrainDataT[1].shape,\n",
    "      \"\\nLength of whole futured (targets) list:\",len(allfuturedTrainT),\", and shape of output\",allfuturedTrainT[1].shape)\n",
    "print(\"\\nList length of whole testSet:\",len(testSet),\", and shape of input\",testSet[1].shape,\n",
    "      \"\\nLength of whole futured test (targets) list:\",len(test_futured),\", and shape of output\",test_futured[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A-2.npy', 6560]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSetIdx[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and futured:\n",
      "21229 21229\n",
      "Validation data and futured:\n",
      "5307 5307\n",
      "Test data and futured:\n",
      "86104 86104\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for the validation set\n",
    "valP            = 0.2 # Select 20% of the indices for validation\n",
    "val_indices = random.sample(range(len(alltrainDataT)), k=int(len(alltrainDataT) * valP))  \n",
    "# Split the data into training and validation sets\n",
    "trainSet, validSet, train_futured, val_futured = [], [], [], []\n",
    "for i in range(len(alltrainDataT)):\n",
    "    if i in val_indices:\n",
    "        validSet.append(alltrainDataT[i])\n",
    "        val_futured.append(allfuturedTrainT[i])\n",
    "    else:\n",
    "        trainSet.append(alltrainDataT[i])\n",
    "        train_futured.append(allfuturedTrainT[i])\n",
    "\n",
    "print(\"Training data and futured:\")\n",
    "print(len(trainSet),len(train_futured))\n",
    "print(\"Validation data and futured:\")\n",
    "print(len(validSet),len(val_futured))\n",
    "print(\"Test data and futured:\")\n",
    "print(len(testSet),len(test_futured))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "BATCH_SIZE                  = 128\n",
    "lr                          = 0.005\n",
    "\n",
    "trainset            = MarinaDataset(trainSet,train_futured)\n",
    "trainloader         = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True)      \n",
    " \n",
    "validset            = MarinaDataset(validSet,val_futured)\n",
    "validloader         = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "testset            = MarinaDataset(testSet,test_futured)\n",
    "testloader         = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 \t Training Loss: 0.208068 \t Validation Loss: 0.088590\n",
      "\t\t Validation Loss Decreased (inf --> 0.088590)\n",
      "Epoch  2 \t Training Loss: 0.089783 \t Validation Loss: 0.108595\n",
      "Epoch  3 \t Training Loss: 0.086261 \t Validation Loss: 0.083548\n",
      "\t\t Validation Loss Decreased (0.088590 --> 0.083548)\n",
      "Epoch  4 \t Training Loss: 0.084065 \t Validation Loss: 0.083274\n",
      "\t\t Validation Loss Decreased (0.083548 --> 0.083274)\n",
      "Epoch  5 \t Training Loss: 0.084041 \t Validation Loss: 0.080072\n",
      "\t\t Validation Loss Decreased (0.083274 --> 0.080072)\n",
      "Epoch  6 \t Training Loss: 0.083146 \t Validation Loss: 0.082820\n",
      "Epoch  7 \t Training Loss: 0.081531 \t Validation Loss: 0.080853\n",
      "Epoch  8 \t Training Loss: 0.080565 \t Validation Loss: 0.083734\n",
      "Epoch  9 \t Training Loss: 0.082580 \t Validation Loss: 0.089873\n",
      "Epoch 10 \t Training Loss: 0.080983 \t Validation Loss: 0.082015\n",
      "Epoch 11 \t Training Loss: 0.080673 \t Validation Loss: 0.085646\n",
      "Epoch 12 \t Training Loss: 0.080759 \t Validation Loss: 0.080977\n",
      "Epoch 13 \t Training Loss: 0.079540 \t Validation Loss: 0.080020\n",
      "\t\t Validation Loss Decreased (0.080072 --> 0.080020)\n",
      "Epoch 14 \t Training Loss: 0.080535 \t Validation Loss: 0.080517\n",
      "Epoch 15 \t Training Loss: 0.079901 \t Validation Loss: 0.084432\n",
      "Epoch 16 \t Training Loss: 0.080478 \t Validation Loss: 0.081378\n",
      "Epoch 17 \t Training Loss: 0.081046 \t Validation Loss: 0.082924\n",
      "Epoch 18 \t Training Loss: 0.080624 \t Validation Loss: 0.084479\n",
      "Epoch 19 \t Training Loss: 0.085080 \t Validation Loss: 0.084474\n",
      "Epoch 20 \t Training Loss: 0.082551 \t Validation Loss: 0.087581\n",
      "Epoch 21 \t Training Loss: 0.080470 \t Validation Loss: 0.080651\n",
      "Epoch 22 \t Training Loss: 0.080210 \t Validation Loss: 0.081850\n",
      "Epoch 23 \t Training Loss: 0.080893 \t Validation Loss: 0.079977\n",
      "\t\t Validation Loss Decreased (0.080020 --> 0.079977)\n",
      "Epoch 24 \t Training Loss: 0.079810 \t Validation Loss: 0.079449\n",
      "\t\t Validation Loss Decreased (0.079977 --> 0.079449)\n",
      "Epoch 25 \t Training Loss: 0.078995 \t Validation Loss: 0.082536\n",
      "Epoch 26 \t Training Loss: 0.079618 \t Validation Loss: 0.080703\n",
      "Epoch 27 \t Training Loss: 0.079320 \t Validation Loss: 0.083079\n",
      "Epoch 28 \t Training Loss: 0.080765 \t Validation Loss: 0.080726\n",
      "Epoch 29 \t Training Loss: 0.079241 \t Validation Loss: 0.081468\n",
      "Epoch 30 \t Training Loss: 0.078998 \t Validation Loss: 0.080755\n",
      "Finished Training\n",
      "Total Execution Time: 600.74 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model           = modeMARINA()\n",
    "model           = model.to(device)\n",
    "criterion       = nn.MSELoss()\n",
    "optimizer       = optim.Adam(model.parameters(), lr=lr)\n",
    "min_valid_loss  = np.inf\n",
    "epoch           = 30       # From the figure 7 in the paper.\n",
    "loss_history    = []\n",
    "\n",
    "start_time = time.time() # Setting starting point for finding the execution time\n",
    "\n",
    "for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    loss_history.append(running_loss / len(trainloader))\n",
    "    print(f'Epoch {epoch+1:2d} \\t Training Loss: {running_loss / len(trainloader):.6f} \\t Validation Loss: {valid_loss / len(validloader):.6f}')\n",
    "\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'\\t\\t Validation Loss Decreased ({min_valid_loss/len(validloader):.6f} --> {valid_loss/len(validloader):.6f})')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        # torch.save(model.state_dict(),'saved_model.pth')\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total Execution Time: {execution_time:.2f} seconds\")\n",
    "\n",
    "# Plotting the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss History')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING MSE\n",
    "def calculate_mse(model, testloader):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            mse += torch.mean((outputs - labels) ** 2).item()\n",
    "\n",
    "    mse /= len(testloader)\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.073802\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mse_score = calculate_mse(model, testloader)\n",
    "print(f\"MSE: {mse_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86104 torch.Size([25, 1])\n",
      "86104 torch.Size([25, 100])\n"
     ]
    }
   ],
   "source": [
    "print(len(test_futured),test_futured[0].shape)\n",
    "print(len(testSet),testSet[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        for i in range(len(val)):\n",
    "            if val[i] == value:\n",
    "                return key\n",
    "    return None  # Value not found in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = test_datas.keys()\n",
    "default_value = []  # Default empty list\n",
    "anomalies = {key: default_value for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies[\"A-1.npy\"].append(2323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2132, 2132, 2323]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies[\"A-1.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = 0\n",
    "for data in testloader:\n",
    "    if ll < 1:\n",
    "        inputs, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyNL,valueNL = [],[]\n",
    "keys = test_datas.keys()\n",
    "default_value = []  # Default empty list\n",
    "#anomalies = {key: default_value for key in keys}\n",
    "anomalies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies09 = {}\n",
    "[keyN, valueN] =  testSetIdx[1]\n",
    "anomalies09[keyN] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalies = {key: default_value for key in keys}\n",
    "anomalies1_875 = {}\n",
    "i = 0\n",
    "ii = 0\n",
    "threshold = 1.875\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        if ii < 8640:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #compare output with labels using frobenius norm\n",
    "            frob_error  =  torch.sqrt(torch.abs(torch.sum(outputs ** 2 - labels ** 2)))\n",
    "            #this if else is for catching the beginning and end of the sequences\n",
    "            if( frob_error > threshold ):\n",
    "                [keyN, valueN] =  testSetIdx[ii]\n",
    "                if keyN not in anomalies1_875:\n",
    "                    anomalies1_875[keyN] = []\n",
    "                anomalies1_875[keyN].append(valueN)\n",
    "            ii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalies1_87[\"A-1.npy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_datas[\"A-1.npy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4119)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frob_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-1.npy 150\n"
     ]
    }
   ],
   "source": [
    "[keyN, valueN] =  testSetIdx[10]\n",
    "print(keyN, valueN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73803"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalies[\"A-3.npy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test each\n",
    "\n",
    "#returns the anomaly pairs and how many are samples there combined \n",
    "def test_run(model , testloader , threshold = 0.7):\n",
    "    model.eval()\n",
    "    anomalies = []\n",
    "    total_sample = 0\n",
    "    is_start = True\n",
    "    anomaly_pair = []\n",
    "    ret_total_sample = 0 \n",
    "    #labels\n",
    "    labels_pandas = pd.read_csv(LABELS_FILEPATH)\n",
    "    label_index = 0\n",
    "    ii = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #compare output with labels using frobenius norm\n",
    "            frob_error  =  torch.sqrt(torch.abs(torch.sum(outputs ** 2 - labels ** 2)))\n",
    "            #this if else is for catching the beginning and end of the sequences\n",
    "            if( frob_error > threshold ):\n",
    "                testSetIdx[ii]\n",
    "                if( is_start ):\n",
    "                    anomaly_pair.append(total_sample)\n",
    "                    is_start = False\n",
    "            else:\n",
    "                if( not is_start):\n",
    "                    anomaly_pair.append(total_sample )\n",
    "                    is_start = True\n",
    "                    anomalies.append(anomaly_pair)\n",
    "                    anomaly_pair = []\n",
    "            total_sample += zeta\n",
    "            if( total_sample == labels_pandas.loc[:,\"num_values\"][label_index]):\n",
    "                label_index += 1 \n",
    "                ret_total_sample += total_sample\n",
    "                total_sample = 0\n",
    "                \n",
    "                anomaly_pair.append(total_sample )\n",
    "                is_start = True\n",
    "                anomalies.append(anomaly_pair)\n",
    "                anomaly_pair = []\n",
    "            ii += 1\n",
    "    return anomalies , ret_total_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1708],\n",
       "  [3271, 7407],\n",
       "  [8278, 0],\n",
       "  [0, 6391],\n",
       "  [0],\n",
       "  [742, 6985],\n",
       "  [0],\n",
       "  [1852, 4915],\n",
       "  [6424, 0],\n",
       "  [0, 0],\n",
       "  [0, 4370],\n",
       "  [6021, 0],\n",
       "  [0, 946],\n",
       "  [2588, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0]],\n",
       " 82981)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "anomalies , total_sample = test_run(model , testloader)\n",
    "anomalies , total_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517764"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels\n",
    "labels_pandas = pd.read_csv(LABELS_FILEPATH)\n",
    "labels_pandas.head(82)\n",
    "labels_pandas.loc[:,\"num_values\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b369e7963f7abcd480fad95d5beb7b146f8ec315fde1b361e4f21d5ea962be01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
